{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Code aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Roll up CPT to CCS\n",
    "The original mapping table provides mappings in a range format ('T10001-T10004' -> 128). Therefore, we have to parse this format at first and then create our mapping table.\n",
    "\n",
    "Please download the original mapping table from HCUP (https://www.hcup-us.ahrq.gov/toolssoftware/ccs_svcsproc/ccssvcproc.jsp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPT-to-CCS mapppings:\n",
      "     cpt ccs\n",
      "0  61000   1\n",
      "1  61001   1\n",
      "2  61020   1\n",
      "3  61026   1\n",
      "4  61050   1\n",
      "5  61055   1\n",
      "6  61105   1\n",
      "7  61108   1\n",
      "8  61120   1\n",
      "9  61150   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def roll_cpt2ccs(output_path):\n",
    "    # path of the original mapping table\n",
    "    path = 'CCS_services_procedures_v2021-1.csv'\n",
    "    \n",
    "    # load the original mapping table\n",
    "    cols = ['Code Range','CCS','CCS Label']\n",
    "    type_setting = {'Code Range':str, 'CCS': int}\n",
    "    original_table = pd.read_csv(path, usecols=type_setting.keys(), skiprows=1,\n",
    "                dtype=type_setting, index_col=False)\n",
    "    \n",
    "    # the final rolling-up table\n",
    "    cpt2ccs = []\n",
    "    \n",
    "    for line in original_table.itertuples(False):\n",
    "        # [a, b] is a continuous sequence of CPTs rolled up to a CCS\n",
    "        a, b = line[0].strip('\\'').split('-')\n",
    "        ccs_code = line[1]\n",
    "        \n",
    "        if a == b:      # the sequence has only one CPT\n",
    "            cpt2ccs.append([a, ccs_code])\n",
    "        else:           # the sequence has more than one CPTs\n",
    "            a = int(a)\n",
    "            b = int(b)\n",
    "            for i in range(a, b+1):\n",
    "                cpt2ccs.append([i, ccs_code])  \n",
    "    \n",
    "    # output the result to a csv file\n",
    "    cpt2ccs = pd.DataFrame(cpt2ccs, columns=['cpt', 'ccs'], dtype='str')\n",
    "    cpt2ccs.to_csv(output_path, index=False)\n",
    "    \n",
    "    return cpt2ccs\n",
    "\n",
    "\n",
    "# demo of code aggregation\n",
    "output_path = 'cpt2ccs_rollup.csv'\n",
    "cpt2ccs = roll_cpt2ccs(output_path)\n",
    "\n",
    "print('\\nCPT-to-CCS mapppings:')\n",
    "print(cpt2ccs.iloc[:10, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Roll up ICD to PheCode\n",
    "Since the original mapping table provides mappings directly, we can filter wanted rows and columns without extra operations.\n",
    "\n",
    "Please download the original mapping table from PheWAS (https://phewascatalog.org/phecodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICD9-to-PheCode mapppings:\n",
      "   ICD9 PheCode\n",
      "0   001     008\n",
      "1  0010     008\n",
      "2  0011     008\n",
      "3  0019     008\n",
      "4   002     008\n",
      "5  0020   008.5\n",
      "6  0021     008\n",
      "7  0022     008\n",
      "8  0023     008\n",
      "9  0029     008\n",
      "\n",
      "ICD10-to-PheCode mapppings:\n",
      "   icd10cm phecode\n",
      "0  S0522XD   870.1\n",
      "1  S01101S   870.1\n",
      "2  S01102S   870.1\n",
      "3  S0522XA   870.1\n",
      "4  S01149S   870.1\n",
      "5  S0561XS   870.1\n",
      "6  S0560XD   870.1\n",
      "7  S01111D   870.1\n",
      "8  S01129S   870.1\n",
      "9    S0110   870.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def roll_icd2phe(icd9_output_path, icd10_output_path):\n",
    "    ### roll up ICD-9 to PheCode\n",
    "    # load the original table\n",
    "    path = 'phecode_icd9_rolled.csv'\n",
    "    df_icd9 = pd.read_csv(path, usecols=['ICD9', 'PheCode'],\n",
    "                          dtype='str')\n",
    "    df_icd9.loc[:, 'ICD9'] = df_icd9.loc[:, 'ICD9'].apply(lambda x:x.replace('.', ''))\n",
    "    \n",
    "    # remove empty line (NA) and duplicate ICDs\n",
    "    df_icd9.dropna(inplace=True)\n",
    "    df_icd9.drop_duplicates(['ICD9'], keep='first', inplace=True)\n",
    "    \n",
    "    # output the result\n",
    "    df_icd9.to_csv(icd9_output_path, index=False)\n",
    "    \n",
    "    \n",
    "    ### roll up ICD-10-CM to PheCode\n",
    "    # load the original table\n",
    "    path = 'Phecode_map_v1_2_icd10cm_beta.csv'\n",
    "    df_icd10 = pd.read_csv(path, usecols=['icd10cm', 'phecode'],\n",
    "                           dtype='str', encoding='unicode_escape')\n",
    "    \n",
    "    # remove the [.] in ICD code for MIMIC rolling up. You may not need to do so in your project\n",
    "    df_icd10.loc[:, 'icd10cm'] = df_icd10.loc[:, 'icd10cm'].apply(lambda x:x.replace('.', ''))\n",
    "    \n",
    "    # remove empty line (NA) and duplicate ICDs\n",
    "    df_icd10.dropna(inplace=True)\n",
    "    df_icd10.drop_duplicates(['icd10cm'], keep='first', inplace=True)\n",
    "    \n",
    "    # output the result\n",
    "    df_icd10.to_csv(icd10_output_path, index=False)\n",
    "    \n",
    "    return df_icd9, df_icd10\n",
    "\n",
    "\n",
    "icd9_output_path = 'icd92phe_rollup.csv'\n",
    "icd10_output_path = 'icd102phe_rollup.csv'\n",
    "icd92phe, icd102phe = roll_icd2phe(icd9_output_path, icd10_output_path)\n",
    "\n",
    "print('\\nICD9-to-PheCode mapppings:')\n",
    "print(icd92phe.iloc[:10, :])\n",
    "\n",
    "print('\\nICD10-to-PheCode mapppings:')\n",
    "print(icd102phe.iloc[:10, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Roll up ICD-10-PCS and ICD-9-CM to CCS\n",
    "For procedure ICD codes, we need two original mapping tables to aggregate them to CCS codes. These original tables provide mappings directly, so we can filter wanted rows and columns without extra operations.\n",
    "\n",
    "Please download original mapping tables from HCUP. \n",
    "\n",
    "(ICD-9-CM: https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp) \n",
    "\n",
    "(ICD-10-PCS: https://www.hcup-us.ahrq.gov/toolssoftware/ccs10/ccs10.jsp)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICD10PCS-to-CCS mapppings:\n",
      "  icd10pcs ccs\n",
      "0  00800ZZ   1\n",
      "1  00803ZZ   1\n",
      "2  00804ZZ   1\n",
      "3  00870ZZ   1\n",
      "4  00873ZZ   1\n",
      "5  00874ZZ   1\n",
      "6  00880ZZ   1\n",
      "7  00883ZZ   1\n",
      "8  00884ZZ   1\n",
      "9  008F0ZZ   1\n",
      "\n",
      "ICD9CM-to-CCS mapppings:\n",
      "   icd9cm ccs\n",
      "1    0101   1\n",
      "2    0109   1\n",
      "3    0121   1\n",
      "4    0122   1\n",
      "5    0123   1\n",
      "6    0124   1\n",
      "7    0125   1\n",
      "8    0126   1\n",
      "9    0127   1\n",
      "10   0128   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def roll_icd10pcs2ccs(output_path):\n",
    "    # load the original table\n",
    "    path = 'ccs_pr_icd10pcs_2020_1.csv'\n",
    "    usecols = [\"'ICD-10-PCS CODE'\", \"'CCS CATEGORY'\"]\n",
    "    icd10pcs2ccs = pd.read_csv(path, usecols=usecols,\n",
    "                           dtype='str', encoding='utf8', index_col=False)\n",
    "    icd10pcs2ccs.rename(\n",
    "        {usecols[0]: 'icd10pcs', usecols[1]: 'ccs'}, axis=1, inplace=True)\n",
    "    \n",
    "    # remove ['] in the table\n",
    "    icd10pcs2ccs.loc[:, 'icd10pcs'] = icd10pcs2ccs.loc[:, 'icd10pcs'].apply(lambda x:x.replace('\\'', '').strip())\n",
    "    icd10pcs2ccs.loc[:, 'ccs'] = icd10pcs2ccs.loc[:, 'ccs'].apply(lambda x:x.replace('\\'', '').strip())\n",
    "\n",
    "    # remove empty line (NA) and duplicate ICDs\n",
    "    icd10pcs2ccs.dropna(inplace=True)\n",
    "    icd10pcs2ccs.drop_duplicates(['icd10pcs'], keep='first', inplace=True)\n",
    "    \n",
    "    # output the result\n",
    "    icd10pcs2ccs.to_csv(output_path, index=False)\n",
    "    \n",
    "    return icd10pcs2ccs\n",
    "\n",
    "\n",
    "def roll_icd9cm2ccs(output_path):\n",
    "    # load the original table\n",
    "    path = '$prref 2015.csv'\n",
    "    usecols = [\"'ICD-9-CM CODE'\", \"'CCS CATEGORY'\"]\n",
    "    icd9cm2ccs = pd.read_csv(path, usecols=usecols, skiprows=1,\n",
    "                           dtype='str', encoding='utf8', index_col=False)\n",
    "    icd9cm2ccs.rename(\n",
    "        {usecols[0]: 'icd9cm', usecols[1]: 'ccs'}, axis=1, inplace=True)\n",
    "    \n",
    "    # remove ['] in the table\n",
    "    icd9cm2ccs.loc[:, 'icd9cm'] = icd9cm2ccs.loc[:, 'icd9cm'].apply(lambda x:x.replace('\\'', '').strip())\n",
    "    icd9cm2ccs.loc[:, 'ccs'] = icd9cm2ccs.loc[:, 'ccs'].apply(lambda x:x.replace('\\'', '').strip())\n",
    "\n",
    "    # remove empty line (NA) and duplicate ICDs\n",
    "    icd9cm2ccs.dropna(inplace=True)\n",
    "    icd9cm2ccs = icd9cm2ccs[icd9cm2ccs['ccs'] != '0']\n",
    "    icd9cm2ccs.drop_duplicates(['icd9cm'], keep='first', inplace=True)\n",
    "    \n",
    "    # output the result\n",
    "    icd9cm2ccs.to_csv(output_path, index=False)\n",
    "    \n",
    "    return icd9cm2ccs\n",
    "\n",
    "\n",
    "output_path = 'icd10pcs2ccs_rollup.csv'\n",
    "icd10pcs2ccs = roll_icd10pcs2ccs(output_path)\n",
    "print('\\nICD10PCS-to-CCS mapppings:')\n",
    "print(icd10pcs2ccs.iloc[:10, :])\n",
    "\n",
    "output_path = 'icd9cm2ccs_rollup.csv'\n",
    "icd9cm2ccs = roll_icd9cm2ccs(output_path)\n",
    "print('\\nICD9CM-to-CCS mapppings:')\n",
    "print(icd9cm2ccs.iloc[:10, :])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Roll up NDC to RxNorm\n",
    "To roll up NDC codes to RxNorm codes, we have to map RxNorm codes to their ingredients and then aggregate NDC to RxNorm.\n",
    "First, we need an ingredient mapping table to map all RxNorms to their ingredient. Here, we provide this mapping tables directly.\n",
    "\n",
    "Then, in function *roll_ndc2rxnorm*, we make use of both obsolete mappings and non-obsolete ones in \"RXSAT.RRF\". \n",
    "The reason we include obsolete mappings is that MIMIC data are collected between 2008 to 2019, and these obsolete mappings might be helpful to code aggregation. \n",
    "Because RxNorm presents the relation between NDC and RxNorm explicitly, we do not need to do extra operations except adding obsolete mappings and mapping RxNorm ingredients.\n",
    "\n",
    "Please download RxNorm files from their offical website (https://www.nlm.nih.gov/research/umls/rxnorm/docs/rxnormfiles.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating NDC-to-RxNorm mapping table...\n",
      "total length 7222434\n",
      "num of CUI 108660\n",
      "valid table size 260008\n",
      "num of valid CUI 19108\n",
      "obsolete table size 449515\n",
      "num of obsolete CUI 29342\n",
      "final size 490361\n",
      "final CUIs 34882\n",
      "\n",
      "NDC-to-RxNorm mapppings:\n",
      "                ATV RXCUI\n",
      "810799  00295117904  5499\n",
      "810800  00295117916  5499\n",
      "810801  00363026816  5499\n",
      "810802  00363026832  5499\n",
      "810803  00363087143  5499\n",
      "810804  00363087145  5499\n",
      "810805  00363087150  5499\n",
      "810806  00363087199  5499\n",
      "810807  00395111316  5499\n",
      "810808  00395111328  5499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def roll_ndc2rxnorm(ingredient_path, output_path):\n",
    "    # load the original table\n",
    "    print('Generating NDC-to-RxNorm mapping table...')\n",
    "    \n",
    "    path = 'rxnorm/rrf/RXNSAT.RRF'\n",
    "    cols = ['RXCUI','LUI','SUI','RXAUI','STYPE','CODE','ATUI','SATUI','ATN','SAB','ATV','SUPPRESS','CVF']\n",
    "    setting = {'RXCUI': int, 'SUPPRESS': str, 'ATN':str,'SAB':str,'ATV':str}\n",
    "    table = pd.read_csv(path, names=cols, usecols=setting.keys(), sep='|',\n",
    "            dtype=setting, index_col=False)\n",
    "    print('total length', table.shape[0])\n",
    "    \n",
    "    # get rows with NDC information\n",
    "    table = table.loc[(table['ATN'] == 'NDC')]\n",
    "    print('num of CUI', table['RXCUI'].drop_duplicates(keep='first', inplace=False).shape[0])\n",
    "    \n",
    "    # separate obsolete and non-obsolete mappings\n",
    "    valid = (table['SAB'] == 'RXNORM') & (table['SUPPRESS'] == 'N')\n",
    "    table_obsolete = table.loc[~valid]\n",
    "    table = table.loc[valid]\n",
    "    print('valid table size', table.shape[0])\n",
    "    \n",
    "    # number of non-obsolete mappings\n",
    "    num = table['RXCUI'].drop_duplicates(keep='first', inplace=False)\n",
    "    print('num of valid CUI', num.shape[0])\n",
    "    \n",
    "    # get obsolete mappings\n",
    "    table_obsolete = table_obsolete.loc[(table_obsolete['ATV'].str.len() == 11) & table_obsolete['ATV'].str.isdigit()] \n",
    "    print('obsolete table size', table_obsolete.shape[0])\n",
    "    # number of obsolete mappings\n",
    "    num = table_obsolete['RXCUI'].drop_duplicates(keep='first', inplace=False)\n",
    "    print('num of obsolete CUI', num.shape[0])\n",
    "    \n",
    "    # merge obsolete and non-obsolete mappings\n",
    "    table = table.append(table_obsolete)\n",
    "    table.drop_duplicates(['ATV'], keep='first', inplace=True)\n",
    "    print('final size', table.shape[0])\n",
    "    print('final CUIs', table['RXCUI'].drop_duplicates(keep='first', inplace=False).shape[0])\n",
    "\n",
    "    # map CUIs to their ingredients\n",
    "    ingredient = pd.read_csv(ingredient_path, usecols=['base','ingredient'],\n",
    "            dtype=setting, index_col=False)\n",
    "    \n",
    "    # update CUIs\n",
    "    dic = {line[0]:line[1] for line in ingredient.itertuples(False)}\n",
    "    table['RXCUI'] = table['RXCUI'].apply(lambda x:dic.get(x, x))\n",
    "    \n",
    "    # output the final result\n",
    "    table = table.loc[:, ['ATV', 'RXCUI']]\n",
    "    table.drop_duplicates(keep='first', inplace=True)\n",
    "    table.to_csv(output_path, sep=',', columns=['ATV', 'RXCUI'], index=False, header=['ndc', 'rxcui'])\n",
    "    \n",
    "    return table\n",
    "\n",
    "ingredient_path = 'rxnorm/ingredient.csv'\n",
    "output_path = 'ndc2rxnorm_rollup.csv'\n",
    "ndc2rxnorm = roll_ndc2rxnorm(ingredient_path, output_path)\n",
    "\n",
    "print('\\nNDC-to-RxNorm mapppings:')\n",
    "print(ndc2rxnorm.iloc[:10, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
